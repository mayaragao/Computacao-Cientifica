{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-r40IxEY5Gt7"
      },
      "source": [
        "![CC-BY-SA](https://mirrors.creativecommons.org/presskit/buttons/88x31/svg/by-sa.svg)\n",
        "\n",
        "\n",
        "This notebook was created by [Bernardo Freitas Paulo da Costa](http://www.im.ufrj.br/bernardofpc),\n",
        "and is licensed under Creative Commons BY-SA."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mTtZw3aA5GuA"
      },
      "source": [
        "Antes de enviar este Teste, verifique que tudo está funcionando como esperado.\n",
        "Por exemplo, **rode o código inteiro, do zero**.\n",
        "Para isso, vá no menu, escolha _Kernel_, depois _Restart & Run All_.\n",
        "\n",
        "Verifique, também, que você respondeu todas as questões:\n",
        "* as questões de código têm `YOUR CODE HERE` (e você pode apagar o `raise NotImplemented` ao incluir sua resposta)\n",
        "* as questões discursivas têm \"YOUR ANSWER HERE\"."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ge575ZcA5GuB"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "034b5d1512154e1671944b6d9dadcae8",
          "grade": false,
          "grade_id": "cell-b0cf0d0a7b388d55",
          "locked": true,
          "schema_version": 3,
          "solution": false
        },
        "id": "TKKum0-65GuC"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gzI_upkG5GuD"
      },
      "source": [
        "# Parte 1: Cálculo vetorial\n",
        "\n",
        "## Questão 1: Derivadas direcionais\n",
        "\n",
        "As derivadas direcionais são obtidas por um limite um pouco mais complicado:\n",
        "\n",
        "$$ \\frac{\\partial f}{\\partial v}(x)= \\lim_{h\\to0} \\frac{f(x+hv) - f(x)}{h}. $$\n",
        "\n",
        "(às vezes, também se escreve $\\nabla_v f(x)$ ou $f'_v(x)$ para a derivada direcional.)\n",
        "\n",
        "Generalize a função `df` para que ela calcule derivadas direcionais."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "e598d80754eb7adf4b97b583eb11d823",
          "grade": false,
          "grade_id": "cell-b5f298e9443e23d7",
          "locked": false,
          "schema_version": 3,
          "solution": true
        },
        "id": "RWZ5tgpv5GuE"
      },
      "outputs": [],
      "source": [
        "def df(f,x,v,h=1e-8):\n",
        "    return (f(x+h*v) - f(x))/h"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KgMxYiQQ5GuF"
      },
      "source": [
        "### Algumas funções vetoriais"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "fd9a53fbfc6b36afcfdaa7e931e55a0a",
          "grade": false,
          "grade_id": "cell-45cfe22bc50ed809",
          "locked": true,
          "schema_version": 3,
          "solution": false
        },
        "id": "BQY4nQ9H5GuF"
      },
      "outputs": [],
      "source": [
        "def norm1(x):\n",
        "    return np.sum(np.abs(x))\n",
        "def norm2(x):\n",
        "    return np.sum(x**2)\n",
        "def estranha(x):\n",
        "    x1,x2 = x\n",
        "    return np.cos(x1) + 2*np.sin(x2/2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NmPouXwD5GuH"
      },
      "source": [
        "#### Testes simples"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df(norm2, np.array([3,4]), np.array([0,2]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WiGhYAaBGyMj",
        "outputId": "d2ea3bfe-1044-4ddc-d337-2621a0d4444a"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "15.999999902760464"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "c0835cb7e3ccdc2e1a537ca44afadd3c",
          "grade": true,
          "grade_id": "cell-248d2b2cb16b7b13",
          "locked": true,
          "points": 1,
          "schema_version": 3,
          "solution": false
        },
        "id": "KR-hOtGy5GuI"
      },
      "outputs": [],
      "source": [
        "assert np.isclose(df(norm2, np.array([3,4]), np.array([0,2])), 16)\n",
        "assert np.isclose(df(norm2, np.array([3,4]), np.array([1,-1])), -2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "53896a7dfaa13d93973c04ad208253ca",
          "grade": true,
          "grade_id": "cell-99f4fbbaf3e65ab4",
          "locked": true,
          "points": 1,
          "schema_version": 3,
          "solution": false
        },
        "id": "591zdxWi5GuI"
      },
      "outputs": [],
      "source": [
        "assert np.isclose(df(estranha, np.array([1,2]), np.array([2,1])), -1.1426397161784507)\n",
        "assert np.isclose(df(estranha, np.array([1,2]), np.array([2,1]), h=1e-3), -1.1426397161784507, rtol=2e-3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "964e87965cb4d695d8e24cc392777afd",
          "grade": true,
          "grade_id": "cell-3f795fc1959aa5ee",
          "locked": true,
          "points": 1,
          "schema_version": 3,
          "solution": false
        },
        "id": "PR5SFQtk5GuJ"
      },
      "outputs": [],
      "source": [
        "assert np.isclose(df(norm1, np.array([3,3]), np.array([0,2])), 2)\n",
        "assert np.isclose(df(norm1, np.array([3,3]), np.array([1,-1])), 0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u8ik_oQa5GuK"
      },
      "source": [
        "#### Testando propriedades"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "d4b3ae4de0b54ef0ab37dd95c0f38c9d",
          "grade": true,
          "grade_id": "cell-a2924509bf252fe5",
          "locked": true,
          "points": 1,
          "schema_version": 3,
          "solution": false
        },
        "id": "k3vEBSRP5GuK"
      },
      "outputs": [],
      "source": [
        "assert np.isclose(df(norm2, np.array([0,3]), np.array([1,0])), \n",
        "                  -df(norm2, np.array([0,3]), np.array([-1,0])))\n",
        "\n",
        "assert np.isclose(df(norm1, np.array([0,3]), np.array([1,0])), \n",
        "                  df(norm1, np.array([0,3]), np.array([-1,0])))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8gLzqOYy5GuL"
      },
      "source": [
        "**Pergunta:** Como interpretar (em Cálculo) estas duas últimas igualdades?  Porque a segunda não tem um sinal de menos?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "86a0351ed0b0844617e3f707ae3858c6",
          "grade": true,
          "grade_id": "cell-3cc75fd5044d0a46",
          "locked": false,
          "points": 3,
          "schema_version": 3,
          "solution": true
        },
        "id": "YrAEIeMY5GuL"
      },
      "source": [
        "As duas ultimas igualdades, representam que dentro da norma 2, a derivada direcional no ponto $[0,3]$ vai resultar em sentidos de crescimento ou decrescimento opostos ao analisar as direções (tambem opostas) dadas pelos vetores $[1,0]$ e $[-1,0]$ . Enquanto para a análise da norma 1, essas direções opostas dadas pelos vetores, vai resultar em uma derivada direcional com mesmo sentido de crescimento ou decrescimento.\n",
        "\n",
        "Na segunda igualdade não existe um sinal de menos, ou seja, a derivada direcional (crescimento e decrescimento no eixo das abcissas dado pelos vetores de direção) nesse ponto $[0,3]$ tem o mesmo valor. Como temos uma função de módulo, e sua derivada pode ser dada por $f'(x) = \\frac{|x|}{x} $, nos valores onde sua coordenada é 0, como no eixo das abcissas, temos uma indeterminação (divisao por 0), e portanto a derivada direcional é a mesma, já que estamos analisando os sentidos do eixo das abcissas e no ponto de analise, a coordenada deste eixo se encontra zerada. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gtfg6A7T5GuM"
      },
      "source": [
        "## Questão 2: Gradientes\n",
        "\n",
        "Vamos usar a nova função `df` para calcular [gradientes](https://pt.wikipedia.org/wiki/Gradiente) e outros objetos do cálculo vetorial.\n",
        "\n",
        "Usando a função `len` (para descobrir a dimensão!), implemente `grad(f,x,delta)`,\n",
        "onde cada derivada parcial é calculada com um passo de tamanho $\\delta$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "158a239ef7d636c1df4a2c28d2ffc0ec",
          "grade": false,
          "grade_id": "cell-9e935e4d0b917421",
          "locked": false,
          "schema_version": 3,
          "solution": true
        },
        "id": "t9vn_f335GuN"
      },
      "outputs": [],
      "source": [
        "def grad(f,x,delta=1e-8):\n",
        "  dim = len(x)\n",
        "  g = []\n",
        "\n",
        "  for i in range(dim):\n",
        "    v = np.zeros(dim)\n",
        "    v[i] = 1\n",
        "    #g = np.vstack([g, df(f, x, v , delta )])\n",
        "    g.append(df(f, x, v , delta ))\n",
        "  return np.array(g)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "6a753331565cc668376778b6af0fdeff",
          "grade": true,
          "grade_id": "cell-d2c0bf67345f07ef",
          "locked": true,
          "points": 1,
          "schema_version": 3,
          "solution": false
        },
        "id": "1rueWvnh5GuN"
      },
      "outputs": [],
      "source": [
        "p = np.array([3,4])\n",
        "assert np.allclose(grad(norm2, p, delta=1e-5), 2*p, rtol=1e-5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "66fe6ffe81de807ff7f4a00051e39b9c",
          "grade": true,
          "grade_id": "cell-4ac81ccce97336d5",
          "locked": true,
          "points": 1,
          "schema_version": 3,
          "solution": false
        },
        "id": "dV2MGGBX5GuN"
      },
      "outputs": [],
      "source": [
        "assert np.allclose(grad(norm1, np.array([3,4])), [1,1])\n",
        "assert np.allclose(grad(norm1, np.array([3,-4])), [1,-1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "35f958a4064fe9e7ea96368062dd368f",
          "grade": true,
          "grade_id": "cell-4ff877466a47984b",
          "locked": true,
          "points": 1,
          "schema_version": 3,
          "solution": false
        },
        "id": "VnZ1cCVL5GuP"
      },
      "outputs": [],
      "source": [
        "ans = [-0.14112000805986724, -0.41614683654714246]\n",
        "assert np.allclose(grad(estranha, np.array([3,4]), 1e-8), ans)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "29qTzN2-5GuQ"
      },
      "source": [
        "## Questão 3: Funções vetoriais\n",
        "\n",
        "Agora, vejamos o que acontece quando a função $f$ vai de $R^n$ em $R^m$.\n",
        "Supondo que a função (programada) `f` receba um vetor (de dimensão $n$) e retorne um vetor (de dimensão $m$),\n",
        "dê a fórmula da $j$-ésima coordenada do vetor `df(f,x,v,h)`,\n",
        "onde `df` é a sua função da questão 1.\n",
        "\n",
        "**Sugestão:** use $f(p)[j]$ para a $j$-ésima coordenada do vetor `f(p)`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "1e31cfffe7141d50e54b5e62d16f8aad",
          "grade": true,
          "grade_id": "cell-3a85ad79e947a5f3",
          "locked": false,
          "points": 2,
          "schema_version": 3,
          "solution": true
        },
        "id": "Q7W8wj9n5GuQ"
      },
      "source": [
        "Da questão 1, temos que:\n",
        "\n",
        "$$ df(f,x,v,h) = \\lim_{h\\to0} \\frac{f(x+hv) - f(x)}{h}. $$\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "Supondo agora, que a função programada receba um vetor como parametro de entrada, temos que nossa função $df$ também será um vetor. Desse modo, a $j$-ésima coordenada do vetor $df(f,x,v,h)$, será dada por: \n",
        "\n",
        "$$ df(f,x,v,h)[j] = \\lim_{h\\to 0} \\frac{f(x+hv)[j] - f(x)[j]}{h}$$\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sZtI4wss5GuR"
      },
      "source": [
        "### Mais funções vetoriais"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "599b61774151b0b239e6ec6fa8c83471",
          "grade": false,
          "grade_id": "cell-db343dd2d38af7e1",
          "locked": true,
          "schema_version": 3,
          "solution": false
        },
        "id": "1Dxv4MZt5GuR"
      },
      "outputs": [],
      "source": [
        "def curva1(t):\n",
        "    return np.array([np.cos(t), np.sin(t), t])\n",
        "\n",
        "def superficie1(t):\n",
        "    u,v = t\n",
        "    return np.array([u*np.exp(v-u), v*np.cos(u+v), np.sin(v)])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "fb42ef86ecb30d40a22ceb62b4c5f5cc",
          "grade": true,
          "grade_id": "cell-221511232c88b938",
          "locked": true,
          "points": 1,
          "schema_version": 3,
          "solution": false
        },
        "id": "nebRDW1l5GuS"
      },
      "outputs": [],
      "source": [
        "assert np.allclose(df(superficie1, np.array([0,0]), np.array([1,2])), [1,2,2])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "a1c247b42d2402fb8617bbce801f40d3",
          "grade": true,
          "grade_id": "cell-e77bb4ced51f5cf4",
          "locked": true,
          "points": 1,
          "schema_version": 3,
          "solution": false
        },
        "id": "moBbxQ515GuS"
      },
      "outputs": [],
      "source": [
        "ans = [-0.9092974268256819, -0.41614683654714246, 1.0]\n",
        "assert np.allclose(df(curva1, 2, 1, 1e-5), ans, rtol=2e-5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aTa6_RjE5GuS"
      },
      "source": [
        "## Questão 4: Ordem dos eixos\n",
        "\n",
        "A sua função `grad` deveria retornar um `np.array`, e para a função `superficie1`,\n",
        "de $R^2$ em $R^3$, isso deve dar a matriz com todas as derivadas parciais."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "c2ec68a7d33f7e8313a8fc6251770e0d",
          "grade": false,
          "grade_id": "cell-ed54cea17ee65d19",
          "locked": true,
          "schema_version": 3,
          "solution": false
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OPw-O5Tq5GuS",
        "outputId": "af9bae72-1e43-45f9-f90f-c6a0f0fbbde0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-1.35913059e-05, -2.82230116e-01,  0.00000000e+00],\n",
              "       [ 2.71829542e+00, -1.27222402e+00, -4.16151383e-01]])"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "grad(superficie1, np.array([1,2]), delta=1e-5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hDu5mjr65GuT"
      },
      "source": [
        "Observando o resultado acima, o que você pode dizer sobre as linhas e colunas da matriz gradiente?\n",
        "Elas coincidem com a ordem típica da matriz Jacobiana do cálculo 2?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "129593d1536fbd8748fbff8d918adff2",
          "grade": true,
          "grade_id": "cell-6166bb35f1fafef9",
          "locked": false,
          "points": 2,
          "schema_version": 3,
          "solution": true
        },
        "id": "aJP6mjVC5GuT"
      },
      "source": [
        "Não coincide com a ordem típica da matriz jacobiana, pois a jacobiana dessa função está representada em uma matriz 3x2, enquanto a matriz é 2x3. Desse modo, podemos reparar que o retorno da função grad() na verdade é a matriz jacobiana transposta. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8dZJYr4i5GuT"
      },
      "source": [
        "## Questão 5: Divergente\n",
        "\n",
        "Adapte o cálculo do gradiente para obter o divergente de uma função vetorial de $R^n$ em $R^n$:\n",
        "\n",
        "$$ \\text{div} F(x) = \\sum \\frac{\\partial F_i}{\\partial x_i}(x). $$"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def div(f,x,delta=1e-8):\n",
        "  g = grad(f,x,delta)\n",
        "  dim = len(g)\n",
        "  id = np.identity(dim, dtype=float)\n",
        "  g = g* id\n",
        "  soma = np.sum(g)\n",
        "  return soma"
      ],
      "metadata": {
        "id": "Le4WNqUcJyqP"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "bfe9a1d79cf6d9e066f41056ae346195",
          "grade": false,
          "grade_id": "cell-ce7d02e486736cfb",
          "locked": true,
          "schema_version": 3,
          "solution": false
        },
        "id": "cmAzW4l05GuT"
      },
      "outputs": [],
      "source": [
        "def polar(p):\n",
        "    rho,theta = p\n",
        "    return rho*np.array([np.cos(theta), np.sin(theta)])\n",
        "\n",
        "def gravity(p):\n",
        "    return -p/sum(p**2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "bc682b8251ef00565420a8a1434e04d5",
          "grade": true,
          "grade_id": "cell-dffa4c34454ebdda",
          "locked": true,
          "points": 1,
          "schema_version": 3,
          "solution": false
        },
        "id": "2ddwky7M5GuU"
      },
      "outputs": [],
      "source": [
        "assert np.isclose(div(polar, np.array([1,0]), delta=1e-3), 2, rtol=1e-3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "057994454df6ae89764b5dca4ee8396b",
          "grade": true,
          "grade_id": "cell-f9a201d81750a5f5",
          "locked": true,
          "points": 2,
          "schema_version": 3,
          "solution": false
        },
        "id": "oxYUG1Ro5GuU"
      },
      "outputs": [],
      "source": [
        "gpolar = grad(polar, np.array([1,0]), delta=1e-3)\n",
        "\n",
        "assert np.allclose(gpolar, np.eye(2), rtol=1e-3, atol=1e-3)\n",
        "assert np.sum(np.abs(gpolar - np.eye(2))) > 1e-4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "90aa52ab8ec357cd1a358189daffdab8",
          "grade": true,
          "grade_id": "cell-eed2eda75a0180c0",
          "locked": true,
          "points": 1,
          "schema_version": 3,
          "solution": false
        },
        "id": "FHVjwSLk5GuU"
      },
      "outputs": [],
      "source": [
        "assert np.isclose(div(gravity, np.array([1,2,1]), delta=1e-6), -1/6, rtol=1e-6)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "3312d341b10e6b2c800698abc61e61df",
          "grade": true,
          "grade_id": "cell-230611dfef1de58c",
          "locked": true,
          "points": 1,
          "schema_version": 3,
          "solution": false
        },
        "id": "zKrU39-j5GuU"
      },
      "outputs": [],
      "source": [
        "assert np.isclose(div(gravity, np.array([1,1,1,1,1])), -0.6, rtol=1e-8)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PGcLftlb5GuV"
      },
      "source": [
        "# Parte 2: Mais precisão\n",
        "\n",
        "Se, em vez de usarmos derivadas laterais, usarmos derivadas centrais,\n",
        "deveríamos obter mais precisão na resposta.\n",
        "\n",
        "## Questão 6: Derivadas centrais\n",
        "\n",
        "Modifique as funções `grad` e `div` para serem simétricas:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "3a23f0fc951274a042a7ab23429257b2",
          "grade": false,
          "grade_id": "cell-0bfc6d0b8fbfa039",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "u8efHOh05GuV"
      },
      "outputs": [],
      "source": [
        "def df_sym(f,x,v,h):\n",
        "  return (f(x+v*h) - f(x-v*h))/(2*h)\n",
        "\n",
        "def grad_sym(f,x,delta=1e-5):\n",
        "  dim = len(x)\n",
        "  g = []\n",
        "\n",
        "  for i in range(dim):\n",
        "    v = np.zeros(dim)\n",
        "    v[i] = 1\n",
        "    g.append(df_sym(f, x, v , delta ))\n",
        "  return np.array(g)\n",
        "\n",
        "def div_sym(f,x,delta=1e-5):\n",
        "  g = grad_sym(f,x,delta)\n",
        "  dim = len(g)\n",
        "  id = np.identity(dim, dtype=float)\n",
        "  g = g* id\n",
        "  soma = np.sum(g)\n",
        "  return soma"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "1d06f18b1df9bb377d9d1da6df525dd4",
          "grade": true,
          "grade_id": "cell-ba882b706df528b2",
          "locked": true,
          "points": 1,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "DmBB64Hc5GuV"
      },
      "outputs": [],
      "source": [
        "gpolar = grad_sym(polar, np.array([1,0]), delta=1e-3)\n",
        "\n",
        "assert np.allclose(gpolar, np.eye(2), rtol=1e-6, atol=1e-6)\n",
        "assert np.sum(np.abs(gpolar - np.eye(2))) > 1e-8"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "3c78dc60e2b7dcd6bde606c0416cd4cb",
          "grade": true,
          "grade_id": "cell-8d96aca4375ddfa1",
          "locked": true,
          "points": 1,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "0VM83C7S5GuV"
      },
      "outputs": [],
      "source": [
        "assert np.isclose(div_sym(gravity, np.array([1,2,1])), -1/6, atol=1e-10, rtol=1e-10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "creo9kjP5GuV"
      },
      "source": [
        "## Questão 7: A derivada é linear\n",
        "\n",
        "Sabemos que, se a função $F : R^n \\to R^m$ for derivável,\n",
        "então podemos calcular derivadas direcionais usando a matriz jacobiana $DF(x)$:\n",
        "$$\n",
        "  \\frac{\\partial F}{\\partial v}(x) = DF(x) \\cdot v.\n",
        "$$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "176858b51557a85b1bab3ee5bea5e541",
          "grade": false,
          "grade_id": "cell-c33a91e7e1a57955",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8giSe2PL5GuW",
        "outputId": "38d7a5e5-f991-4e67-9596-8f7b031ea157"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-0.006000000001726846\n",
            "-0.005999999999950489\n",
            "0.0\n",
            "-0.002000000000279556\n"
          ]
        }
      ],
      "source": [
        "x = np.array([1,2])\n",
        "vs = [np.array([1,3]), np.array([3,1]), np.array([1,1]), np.array([1,-1])]\n",
        "\n",
        "for v in vs:\n",
        "    DF_norm2 = grad(norm2, x, delta=1e-3)\n",
        "    parcial  = df(norm2, x, v, h=1e-3)\n",
        "    print(DF_norm2 @ v - parcial)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nZe9jo9X5GuW"
      },
      "source": [
        "Porquê aparece este erro?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "805443dbf7df71e221f5b67290a7dcbd",
          "grade": true,
          "grade_id": "cell-3fefd1494a881def",
          "locked": false,
          "points": 2,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "5PED4Tb_5GuW"
      },
      "source": [
        "O erro aparece porque para cada elemento da matriz, é feito o calculo de df (derivada direcional) com base em algum eixo cartesiano, cálculo que leva algum erro, justamente por conta dos termos que sobram da expansão de taylor da derivada lateral. \n",
        "\n",
        "Assim, ao fazer df para cada direção, estaremos repetindo esse erro em cada elemento do gradiente calculado, ou seja, para cada elemento da matriz retornada pela funcao grad(). \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_8m1GJVl5GuW"
      },
      "source": [
        "Expanda em série de Taylor a fórmula da derivada lateral e a fórmula do \"gradiente lateral\",\n",
        "e encontre uma expressão para o erro entre\n",
        "1. a derivada lateral; e\n",
        "2. a matriz jacobiana vezes o vetor diretor."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "a8beb5813d0e383105e11b5e239f8ff9",
          "grade": true,
          "grade_id": "cell-20a2721b6135ff86",
          "locked": false,
          "points": 2,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "Zwl4fbY95GuW"
      },
      "source": [
        "Nossa fórmula é:\n",
        "$$ \\frac{\\partial f}{\\partial v}(x)= \\lim_{h\\to0} \\frac{f(x+hv) - f(x)}{h} $$\n",
        "\n",
        "\n",
        "$$ df(x, h) = \\frac{f(x+hv) - f(x)}{h} $$\n",
        "\n",
        "\n",
        "expandido em série de Taylor, temos:\n",
        "\n",
        "$$ f(x+h) = f(x)+ f'(x) \\cdot h + \\frac{f''(x)\\cdot h^{2}}{2} + O(h^3) ...$$\n",
        "\n",
        "Logo, \n",
        "\n",
        "\n",
        "$$ df(x, h) = \\frac{f(x+h) - f(x)}{h} = \\frac{f(x)+ f'(x) \\cdot h + \\frac{f''(x)\\cdot h^{2}}{2} + O(h^3) -f(x)}{h} $$\n",
        "\n",
        "\n",
        "\n",
        "$$ df(x, h) =  \\frac{ f'(x) \\cdot h + \\frac{f''(x)\\cdot h^{2}}{2} + O(h^3)}{h} $$\n",
        "\n",
        "\n",
        "$$ df(x, h) =   f'(x)+ \\frac{f''(x)\\cdot h}{2} + O(h^2) $$\n",
        "\n",
        "Como estamos realmente interessados na derivada, temos que o erro será dado pela seguinte parte da expanssão de Taylor:\n",
        "\n",
        "\n",
        "$$ \\epsilon_x = \\frac{f''(x)\\cdot h}{2} + O(h^2) $$ \n",
        "\n",
        "\n",
        "Desse modo, para cada elemento da matriz jacobiana retornada pela funcao grad, temos esse erro. \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zwhcpkgV5GuX"
      },
      "source": [
        "## Questão 8: melhorando a linearidade?\n",
        "\n",
        "Agora, vejamos o que acontece com derivadas simétricas:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "f0450aec413c905c4457b371b20084d4",
          "grade": false,
          "grade_id": "cell-80ab3b6e60b2f549",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UogEuye75GuX",
        "outputId": "ff93fbcf-38ad-4756-c634-285f320c5a76"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-1.7763568394002505e-12\n",
            "-4.440892098500626e-13\n",
            "0.0\n",
            "0.0\n",
            "\n",
            "5.403024694317082e-07\n",
            "-3.3658822395921106e-06\n",
            "0.0\n",
            "-2.220446049250313e-13\n"
          ]
        }
      ],
      "source": [
        "for v in vs:\n",
        "    DF_norm2 = grad_sym(norm2, x, delta=1e-3)\n",
        "    parcial  = df_sym(norm2, x, v, h=1e-3)\n",
        "    print(DF_norm2 @ v - parcial)\n",
        "\n",
        "print()\n",
        "for v in vs:\n",
        "    DF_norm2 = grad_sym(estranha, x, delta=1e-3)\n",
        "    parcial  = df_sym(estranha, x, v, h=1e-3)\n",
        "    print(DF_norm2 @ v - parcial)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZPmGII2J5GuX"
      },
      "source": [
        "O erro é menor, mas não apenas.\n",
        "O que acontece de especial no caso da norma 2?\n",
        "\n",
        "Dica: expanda a série de Taylor para ver qual o erro da derivada central."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "670da6ee955239b6185bd4271c2e3c10",
          "grade": true,
          "grade_id": "cell-3a505f0c8892c673",
          "locked": false,
          "points": 3,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "Q_A1nKzw5GuX"
      },
      "source": [
        "Nossa fórmula é:\n",
        "$$ \\frac{\\partial f}{\\partial v}(x)= \\lim_{h\\to0} \\frac{f(x+hv) - f(x-hv)}{2h} $$\n",
        "\n",
        "\n",
        "$$ df(x, h) = \\frac{f(x+h) - f(x-h)}{2h} $$\n",
        "\n",
        "\n",
        "expandido esses termos em série de Taylor, temos que:\n",
        "\n",
        "$$ f(x+h) = f(x)+ f'(x) \\cdot h + \\frac{f''(x)\\cdot h^{2}}{2} + \\frac{f'''(x)\\cdot h^{3}}{6}  + O(h^4) ...$$\n",
        "\n",
        "\n",
        "\n",
        "$$ f(x -h) = f(x) - f'(x) \\cdot h + \\frac{f''(x)\\cdot h^{2}}{2} - \\frac{f'''(x)\\cdot h^{3}}{6}  + O(h^4) ...$$\n",
        "Logo, \n",
        "\n",
        "\n",
        "$$ df(x, h) = \\frac{f(x+h) - f(x-h)}{2h} = \\frac{(f(x)+ f'(x) \\cdot h + \\frac{f''(x)\\cdot h^{2}}{2} + \\frac{f'''(x)\\cdot h^{3}}{6}  + O(h^4)) - (f(x) - f'(x) \\cdot h + \\frac{f''(x)\\cdot h^{2}}{2} - \\frac{f'''(x)\\cdot h^{3}}{6}  + O(h^4))}{2h} $$\n",
        "\n",
        "\n",
        "\n",
        "$$ df(x, h) = \\frac{f(x)+ f'(x) \\cdot h + \\frac{f''(x)\\cdot h^{2}}{2} + \\frac{f'''(x)\\cdot h^{3}}{6}  + O(h^4) - f(x) + f'(x) \\cdot h - \\frac{f''(x)\\cdot h^{2}}{2} + \\frac{f'''(x)\\cdot h^{3}}{6}  - O(h^4)}{2h} $$\n",
        "\n",
        "Cortando os termos possiveis:\n",
        "\n",
        "\n",
        "$$ df(x, h) = \\frac{ 2 \\cdot( f'(x) \\cdot h + \\frac{f'''(x)\\cdot h^{3}}{6}) }{2h} $$\n",
        "\n",
        "\n",
        "\n",
        "$$ df(x, h) = \\frac{ f'(x) \\cdot h + \\frac{f'''(x)\\cdot h^{3}}{6} }{h} $$\n",
        "\n",
        "$obs:$ ainda existe a parte da expressao $O(h^5)$ que não é cortada, logo:\n",
        "\n",
        "\n",
        "$$ df(x, h) = \\frac{ f'(x) \\cdot h + \\frac{f'''(x)\\cdot h^{3}}{6} + O(h^5)}{h}  $$\n",
        "\n",
        "$$ df(x, h) = f'(x) + \\frac{f'''(x)\\cdot h^{2}}{6} + O(h^4)$$ \n",
        "\n",
        "Como estamos realmente interessados na derivada, temos que o erro da derivada central será dado pela seguinte parte da expansão de Taylor:\n",
        "\n",
        "\n",
        "$$ \\epsilon_x = \\frac{f'''(x)\\cdot h^{2}}{6} + O(h^4)$$ \n",
        "\n",
        "\n",
        "Sendo assim, podemos verificar, que pela expansao de Taylor da derivada central, o erro predominante depende do tamanho de $h$ e da terceira derivada da função:  $f'''(x)$. Logo, em especial na norma 2, temos que a terceira derivada dessa funcao quadrática, será $0$ para cada dimensão do vetor. Enquanto na função estranha, temos alguma função trigonométrica, como a soma entre senos e cossenos, função que tem um valor maximo pré-definido maior que $0$. \n",
        "\n",
        "Por esse motivo, temos que o erro na derivada central da função da norma 2 é tão pequeno, por conta das parcelas da expansao de taylor, que na derivada central, concentra o erro na parcela predominante da terceira derivada, enquanto a expansao de Taylor da derivada central, tem um erro aproximado pela parcela da segunda derivada. Vale lembrar que o erro da expansao de taylor, ainda leva em conta um erro $O(h^2)$ para derivada lateral e $O(h^4)$ para derivada central, que representam os termos nao expandidos da serie de taylor. "
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.5"
    },
    "colab": {
      "name": "MayaraAragao_Teste4.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}